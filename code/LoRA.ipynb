{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install evaluate\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgII2SqqSoYq",
        "outputId": "3f51305c-0c56-4eeb-b5f1-2972473c7f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.2)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2023.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.12.25)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import math"
      ],
      "metadata": {
        "id": "SkYfSGNYLMA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up models\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "XFoe5OyYKZeg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load pretrained gpt2-medium model from huggingface"
      ],
      "metadata": {
        "id": "b0bOXfW9OzdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-medium\")\n",
        "\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "with torch.no_grad():\n",
        "  model.resize_token_embeddings((len(tokenizer)))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "1iLX2jcIM0so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d6524c-d344-4701-d21a-2c7c7dab72a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model = AutoModelForCausalLM.from_pretrained(\"gpt2-medium\")\n",
        "with torch.no_grad():\n",
        "  ft_model.resize_token_embeddings((len(tokenizer)))\n",
        "ft_model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "mtM8QMe9KJBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freeze parameters for LoRA model"
      ],
      "metadata": {
        "id": "9Wph1TmpKYG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "3CjAWJxaNHr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create LoRA attention layer, where LoRA is applied to Q and V values"
      ],
      "metadata": {
        "id": "OX0sEuMPO-fC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LoraConv1d(nn.Module):\n",
        "    def __init__(self, layer, features, rank, alpha):\n",
        "        super().__init__()\n",
        "        self.layer = layer\n",
        "        self.layer.weight.require_grad = False\n",
        "        self.lora_a = nn.Parameter(layer.weight.new_zeros((features, rank)))\n",
        "        self.lora_b = nn.Parameter(layer.weight.new_zeros((rank, features)))\n",
        "\n",
        "        self.lora_a2 = nn.Parameter(layer.weight.new_zeros((features, rank)))\n",
        "        self.lora_b2 = nn.Parameter(layer.weight.new_zeros((rank, features)))\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.lora_a, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_b)\n",
        "        nn.init.kaiming_uniform_(self.lora_a2, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_b2)\n",
        "        self.alpha = alpha / rank\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = self.lora_a.device\n",
        "        s = x.shape\n",
        "        wq = x @ self.lora_a @ self.lora_b\n",
        "        wv = x @ self.lora_a2 @ self.lora_b2\n",
        "        lr_qkv = torch.concat((wq, torch.zeros((s)).to(device), wv), dim=-1)\n",
        "        return self.layer(x) + self.alpha * (lr_qkv)\n"
      ],
      "metadata": {
        "id": "PdKOwpLwOWHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace Attention weights with LoRA version of attention"
      ],
      "metadata": {
        "id": "MWLdDMNTKk09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank = 4\n",
        "alpha = 32\n",
        "c_attn_in = 1024\n",
        "for block in model.transformer.h:\n",
        "    block.attn.c_attn = LoraConv1d(block.attn.c_attn, c_attn_in, rank, alpha)"
      ],
      "metadata": {
        "id": "mVxeJ-G7Kj8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qiaYihLOjH7",
        "outputId": "1360d581-f171-4321-c5fa-c44da51630fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50258, 1024)\n",
              "    (wpe): Embedding(1024, 1024)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50258, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "ft_trainable_params = sum(p.numel() for p in ft_model.parameters())\n",
        "print(\"Number of trainable params in LoRA model:\")\n",
        "print(lora_trainable_params)\n",
        "print(\"Number of trainable params in regular model:\")\n",
        "print(ft_trainable_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I78tIeRAO3CO",
        "outputId": "4893849e-28fe-4f93-b9ed-74a0f000656d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "393216"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and process dataset"
      ],
      "metadata": {
        "id": "PEnsoSZkK7vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "og_dataset = load_dataset(\"e2e_nlg\")"
      ],
      "metadata": {
        "id": "1wkvxmzj0W0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "og_dataset = og_dataset.rename_column(\"meaning_representation\", \"text\")\n",
        "og_dataset = og_dataset.rename_column(\"human_reference\", \"labels\")"
      ],
      "metadata": {
        "id": "Fhbe8Mka06yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine text and labels to single sentence, with = as sep token"
      ],
      "metadata": {
        "id": "BMp86yHiPN9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_end(example):\n",
        "  example[\"text\"] = example[\"text\"] + \" = \"\n",
        "  example[\"labels\"] = example[\"labels\"] + tokenizer.eos_token\n",
        "  return example\n",
        "\n",
        "dataset = og_dataset.map(add_end)"
      ],
      "metadata": {
        "id": "nzS7zWOusCf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize dataset"
      ],
      "metadata": {
        "id": "MtlBLl7uPZqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], examples[\"labels\"], padding=\"max_length\", max_length=128, add_special_tokens=True)\n",
        "\n",
        "def tokenize_test(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=False)\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = dataset[\"train\"].map(tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "eval_dataset = dataset[\"validation\"].map(tokenize_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
        "test_dataset = dataset[\"test\"].map(tokenize_test, batched=True, remove_columns=dataset[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "u-jn3pOj2SQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize DataCollator"
      ],
      "metadata": {
        "id": "TjWMu_6MPcWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")"
      ],
      "metadata": {
        "id": "4jOM5_pDEFxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Models"
      ],
      "metadata": {
        "id": "R12ERuncPfGM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training configurations"
      ],
      "metadata": {
        "id": "LyQ7hWloLBmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "weight_decay = 0.01\n",
        "dropout_prob = 0.1\n",
        "batch_size = 8\n",
        "epoch = 5\n",
        "warmup_steps = 500\n",
        "label_smooth = 0.1\n",
        "learning_r = 0.0002\n",
        "learning_rate_schedule = \"linear\"\n",
        "evaluation_strategy = \"epoch\"\n",
        "\n",
        "\n",
        "beam_size = 10\n",
        "length_penalty = 0.8\n",
        "no_repeat_ngram_size = 4\n",
        "\n",
        "output_dir = '/result/'\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    weight_decay = weight_decay,\n",
        "    learning_rate = learning_r,\n",
        "    evaluation_strategy = evaluation_strategy,\n",
        "    warmup_steps = warmup_steps,\n",
        "    num_train_epochs = epoch,\n",
        "    label_smoothing_factor = 0.1,\n",
        "    save_strategy = \"epoch\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "FXlD96lT-fGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train LoRA model"
      ],
      "metadata": {
        "id": "A_f_6g5ALSY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "s9yLYsc7mjAe",
        "outputId": "e9cccd80-93a8-4106-855a-bd921868edcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
            "  warnings.warn(\n",
            "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='61' max='26290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   61/26290 00:26 < 3:15:14, 2.24 it/s, Epoch 0.01/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f01c7441d20e>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1863\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1866\u001b[0m                 ):\n\u001b[1;32m   1867\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Finetuned model"
      ],
      "metadata": {
        "id": "2twYi8V8LUv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=ft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "HlR99_v-LQQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate results"
      ],
      "metadata": {
        "id": "iHpCT_CrLftH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get References"
      ],
      "metadata": {
        "id": "x3LgizXlLwOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "refs = open(\"refs.txt\", 'w', encoding=\"utf-8\")\n",
        "count = 1\n",
        "indices = [0]\n",
        "#test dataset contains multiple references per input.\n",
        "#indices stores first instance of each input\n",
        "past = dataset[\"test\"][0][\"text\"]\n",
        "for i in range(len(dataset[\"test\"])):\n",
        "  p = dataset[\"test\"][i][\"text\"]\n",
        "  if p != past:\n",
        "    count += 1\n",
        "    indices.append(i)\n",
        "    refs.write(\"\\n\")\n",
        "  past = p\n",
        "  refs.write(dataset[\"test\"][i][\"labels\"])\n",
        "  refs.write(\"\\n\")\n",
        "refs.close()"
      ],
      "metadata": {
        "id": "8r26v69cLr_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Outputs"
      ],
      "metadata": {
        "id": "OnZ81oljMBeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GenerationConfig\n",
        "num_beams = 10\n",
        "length_p = 0.9\n",
        "no_repeat_ngram_size=4\n",
        "\n",
        "gc = GenerationConfig(\n",
        "    max_length=128,\n",
        "    num_beams=num_beams,\n",
        "    length_penalty=length_p,\n",
        "    no_repeat_ngram_size=no_repeat_ngram_size,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        "  )"
      ],
      "metadata": {
        "id": "0Ut748W_MW49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_outputs = []\n",
        "for i in indices:\n",
        "    x = torch.tensor([test_dataset[i][\"input_ids\"], test_dataset[i][\"attention_mask\"]]).to(model.device)\n",
        "    output = model.generate(x, generation_config=gc)\n",
        "    output = tokenizer.decode(output[0]).split(\"=\")[-1] #ignore input\n",
        "    lora_outputs.append(output)\n",
        "assert len(lora_outputs) == count"
      ],
      "metadata": {
        "id": "svEYCiMzNBWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = open(\"outputs.txt\", 'w', encoding='utf-8')\n",
        "for output in pp:\n",
        "  if \"<|\" in output:\n",
        "    new_out = output.split(\"<|\")[0] ## removes padding if present\n",
        "  out.write(new_out)\n",
        "  out.write(\"\\n\")\n",
        "out.close()"
      ],
      "metadata": {
        "id": "utm6Ew5EN3gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_outputs = []\n",
        "for i in indices:\n",
        "    x = torch.tensor([test_dataset[i][\"input_ids\"], test_dataset[i][\"attention_mask\"]]).to(ft_model.device)\n",
        "    output = ft_model.generate(x, generation_config=gc)\n",
        "    output = tokenizer.decode(output[0]).split(\"=\")[-1] #ignore input\n",
        "    ft_outputs.append(output)\n",
        "assert len(ft_outputs) == count"
      ],
      "metadata": {
        "id": "wcmMY1j0NDph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = open(\"ft-outputs.txt\", 'w', encoding='utf-8')\n",
        "for output in pp:\n",
        "  if \"<|\" in output:\n",
        "    new_out = output.split(\"<|\")[0] ## removes padding if present\n",
        "  out.write(new_out)\n",
        "  out.write(\"\\n\")\n",
        "out.close()"
      ],
      "metadata": {
        "id": "fRCxM4i9N48g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Results"
      ],
      "metadata": {
        "id": "moTCtopIOV-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tuetschek/e2e-metrics.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHntq2-CMikl",
        "outputId": "2af6bf13-3045-4dfa-bfa4-3cea9ba33b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'e2e-metrics' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'e2e-metrics')"
      ],
      "metadata": {
        "id": "qPQ9ay4kM-hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r e2e-metrics/requirements.txt"
      ],
      "metadata": {
        "id": "MiRLo54bNIbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L https://cpanmin.us | perl - App::cpanminus\n",
        "!cpanm XML::Twig\n"
      ],
      "metadata": {
        "id": "6QYOyoWHNMQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate LoRA model"
      ],
      "metadata": {
        "id": "TvjmgfIrOfV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/e2e-metrics/measure_scores.py refs.txt lora_outputs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEGpTkC-JPOE",
        "outputId": "418605fe-23f2-41e1-db35-b4ce99a3e8ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 129948 tokens at 337157.27 tokens per second.\n",
            "PTBTokenizer tokenized 17167 tokens at 97048.95 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.449\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.693\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.322\n",
            "Creating temp directory  /tmp/e2e-eval-s04yz03q\n",
            "Running MTEval to compute BLEU & NIST...\n",
            "Use of 'Hyphen' in \\p{} or \\P{} is deprecated because: Supplanted by Line_Break property values; see www.unicode.org/reports/tr14 at /content/e2e-metrics/mteval/mteval-v13a-sig.pl line 993.\n",
            "Use of 'Hyphen' in \\p{} or \\P{} is deprecated because: Supplanted by Line_Break property values; see www.unicode.org/reports/tr14 at /content/e2e-metrics/mteval/mteval-v13a-sig.pl line 993.\n",
            "MT evaluation scorer began on 2024 May 2 at 01:14:46\n",
            "command line:  /content/e2e-metrics/mteval/mteval-v13a-sig.pl -r /tmp/e2e-eval-s04yz03q/mteval_ref.sgm -s /tmp/e2e-eval-s04yz03q/mteval_src.sgm -t /tmp/e2e-eval-s04yz03q/mteval_sys.sgm -f /tmp/e2e-eval-s04yz03q/mteval_log.txt\n",
            "  Evaluation of any-to-en translation using:\n",
            "    src set \"e2e\" (1 docs, 630 segs)\n",
            "    ref set \"e2e\" (45 refs)\n",
            "    tst set \"e2e\" (1 systems)\n",
            "\n",
            "NIST score = 8.6929  BLEU score = 0.6705 for system \"tst\"\n",
            "\n",
            "# ------------------------------------------------------------------------\n",
            "\n",
            "Individual N-gram scoring\n",
            "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
            "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
            " NIST:  5.5804   1.4352   0.7807   0.5119   0.3846   0.2015   0.1263   0.0761   0.0565  \"tst\"\n",
            "\n",
            " BLEU:  0.9335   0.7727   0.6172   0.4828   0.3662   0.2801   0.2251   0.1813   0.1466  \"tst\"\n",
            "\n",
            "# ------------------------------------------------------------------------\n",
            "Cumulative N-gram scoring\n",
            "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
            "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
            " NIST:  5.5804   7.0156   7.7964   8.3083   8.6929   8.8945   9.0208   9.0969   9.1534  \"tst\"\n",
            "\n",
            " BLEU:  0.9192   0.8363   0.7519   0.6705   0.5922   0.5214   0.4615   0.4098   0.3649  \"tst\"\n",
            "MT evaluation scorer ended on 2024 May 2 at 01:15:00\n",
            "\n",
            "Removing temp directory\n",
            "SCORES:\n",
            "==============\n",
            "BLEU: 0.6705\n",
            "NIST: 8.6929\n",
            "METEOR: 0.4493\n",
            "ROUGE_L: 0.6930\n",
            "CIDEr: 2.3218\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Fine Tuned model"
      ],
      "metadata": {
        "id": "xABOMfVhOj37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/e2e-metrics/measure_scores.py refs.txt ft_outputs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqsqhueVi1RK",
        "outputId": "446715be-c148-4ee0-cf49-892bf26fc51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running MS-COCO evaluator...\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...     \n",
            "DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "tokenization...\n",
            "PTBTokenizer tokenized 129948 tokens at 490178.18 tokens per second.\n",
            "PTBTokenizer tokenized 16324 tokens at 101861.22 tokens per second.\n",
            "setting up scorers...\n",
            "computing METEOR score...\n",
            "METEOR: 0.443\n",
            "computing Rouge score...\n",
            "ROUGE_L: 0.688\n",
            "computing CIDEr score...\n",
            "CIDEr: 2.185\n",
            "Creating temp directory  /tmp/e2e-eval-xocg7pm0\n",
            "Running MTEval to compute BLEU & NIST...\n",
            "Use of 'Hyphen' in \\p{} or \\P{} is deprecated because: Supplanted by Line_Break property values; see www.unicode.org/reports/tr14 at /content/e2e-metrics/mteval/mteval-v13a-sig.pl line 993.\n",
            "Use of 'Hyphen' in \\p{} or \\P{} is deprecated because: Supplanted by Line_Break property values; see www.unicode.org/reports/tr14 at /content/e2e-metrics/mteval/mteval-v13a-sig.pl line 993.\n",
            "MT evaluation scorer began on 2024 May 2 at 00:44:51\n",
            "command line:  /content/e2e-metrics/mteval/mteval-v13a-sig.pl -r /tmp/e2e-eval-xocg7pm0/mteval_ref.sgm -s /tmp/e2e-eval-xocg7pm0/mteval_src.sgm -t /tmp/e2e-eval-xocg7pm0/mteval_sys.sgm -f /tmp/e2e-eval-xocg7pm0/mteval_log.txt\n",
            "  Evaluation of any-to-en translation using:\n",
            "    src set \"e2e\" (1 docs, 630 segs)\n",
            "    ref set \"e2e\" (45 refs)\n",
            "    tst set \"e2e\" (1 systems)\n",
            "\n",
            "NIST score = 8.4645  BLEU score = 0.6521 for system \"tst\"\n",
            "\n",
            "# ------------------------------------------------------------------------\n",
            "\n",
            "Individual N-gram scoring\n",
            "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
            "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
            " NIST:  5.4322   1.4157   0.7655   0.4890   0.3621   0.1806   0.1113   0.0695   0.0505  \"tst\"\n",
            "\n",
            " BLEU:  0.9238   0.7584   0.6016   0.4684   0.3539   0.2680   0.2154   0.1773   0.1491  \"tst\"\n",
            "\n",
            "# ------------------------------------------------------------------------\n",
            "Cumulative N-gram scoring\n",
            "        1-gram   2-gram   3-gram   4-gram   5-gram   6-gram   7-gram   8-gram   9-gram\n",
            "        ------   ------   ------   ------   ------   ------   ------   ------   ------\n",
            " NIST:  5.4322   6.8479   7.6134   8.1024   8.4645   8.6451   8.7564   8.8259   8.8764  \"tst\"\n",
            "\n",
            " BLEU:  0.9037   0.8188   0.7335   0.6521   0.5745   0.5041   0.4451   0.3956   0.3541  \"tst\"\n",
            "MT evaluation scorer ended on 2024 May 2 at 00:45:04\n",
            "\n",
            "Removing temp directory\n",
            "SCORES:\n",
            "==============\n",
            "BLEU: 0.6521\n",
            "NIST: 8.4645\n",
            "METEOR: 0.4434\n",
            "ROUGE_L: 0.6876\n",
            "CIDEr: 2.1845\n",
            "\n"
          ]
        }
      ]
    }
  ]
}